<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22>
    <text y=%22.9em%22 font-size=%2290%22>üê∏</text></svg>">
    <meta name="description" content="Employee scheduling and retention analysis" />
    <meta name="author" content="Adri√°n Ochoa Ferri√±o" />
    <title>Projekt 2: Personalmanagement im Einzelhandel</title>
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="https://pyscript.net/releases/2025.3.1/core.css">
    <script type="module" src="https://pyscript.net/releases/2025.3.1/core.js"></script>
</head>

<body>
<py-config>
    packages = ["numpy", "pandas", "scipy", "seaborn"]
    [[fetch]]
    from = 'databases/'
    files = ['corr_matrix_v2.csv']
</py-config>

  <header>
    <nav>
      <ul>
        <li><a href="homepage_neu.html#project-showcase">Projekt-Schaufenster</a></li>
        <li><a class="translation" href="project_2_en.html">English Version</a></li>
      </ul>
    </nav>
  </header>


<section id="homepage">
  <h1>Personalmanagement im Einzelhandel:</h1>
  <h2>Anwendung der Personaleinsatzplanung und Retention-analyse des Personals in mehreren Convenience-Stores innerhalb
  einer Stadt. Wie statistische Analyse- und Datenvisualisierungstechniken dabei helfen k√∂nnen, die Mitarbeiterbindung
  vorherzusagen und Faktoren zu identifizieren, die zur Mitarbeiterfluktuation beitragen.</h2>
    <div class="project-container">
        <h3>Ein aktuelles Ph√§nomen, das in der Einzelhandelsbranche als ‚ÄûBig Quit‚Äú bekannt ist, hat Unternehmen dazu
            veranlasst, nach effektiveren L√∂sungen sowohl f√ºr den Gesch√§ftsbetrieb als auch f√ºr die
            Mitarbeiterzufriedenheit zu suchen. Traditionell haben sich Manager bei der Zuweisung von Ressourcen auf
            Intuition und Erfahrung verlassen ‚Äì ein Ansatz, der oft unzuverl√§ssig und nicht immer optimal ist.
            <br><br>
            Aus diesem Grund setzen Einzelhandelsunternehmen zunehmend auf datengest√ºtzte Strategien zur Optimierung
            des Personalmanagements. Durch die Analyse von Daten zu Mitarbeiterplanung, Verf√ºgbarkeit und Leistung
            wollen sie die Arbeitskosten senken, die Mitarbeiterbindung verbessern und den Kundenservice optimieren.
            <br><br>
            <b>Workforce management (WFM)</b>-Initiativen konzentrieren sich darauf, die Personalbesetzung an den
            Gesch√§ftsanforderungen und der Kundennachfrage auszurichten und gleichzeitig die Arbeitskosten zu
            minimieren. Diese Projekte umfassen in der Regel den Einsatz von Planungsmodellen und Bindungsanalysen zur
            Unterst√ºtzung operativer Entscheidungen.
            <br><br>
            Dank der Digitalisierung im Einzelhandel k√∂nnen komplexe Aufgaben wie die Personalplanung und die Prognose
            der Mitarbeiterbindung nun mithilfe von Datenanalysen und Algorithmen des maschinellen Lernens optimiert
            werden.
        </h3>

        <h3>Die <b>CRISP-DM</b> Methodik bietet einen robusten Rahmen, den Datenwissenschaftler nutzen, um ihre
            Projekte vom Verst√§ndnis des gesch√§ftlichen Kontexts und der technischen Einschr√§nkungen bis hin zur
            Bew√§ltigung komplexer Datenprobleme und der Bewertung der Ergebnisse zu steuern. Durch ein klares
            Verst√§ndnis der Anforderungen der Einzelhandelsbranche in der ersten Phase von CRISP-DM k√∂nnen wichtige
            Faktoren identifiziert und in umsetzbare Erkenntnisse f√ºr die Entwicklung praktischer Datenl√∂sungen
            umgesetzt werden.
            <br><br>
            Durch Datenanalyse k√∂nnen Muster in mitarbeiterbezogenen Daten aufgedeckt werden, die h√§ufig im
            Einzelhandel vorkommen. Gleichzeitig erm√∂glicht maschinelles Lernen eine adaptive Modellierung, sodass
            Manager Zeitpl√§ne in Echtzeit anpassen k√∂nnen. Diese Reaktionsf√§higkeit stellt sicher, dass Mitarbeiter
            dort eingesetzt werden, wo sie am dringendsten ben√∂tigt werden, wodurch Leerlaufzeiten reduziert, die
            Effizienz gesteigert und die Mitarbeiterbindung positiv beeinflusst werden.
            <br><br>
            Dieses Projekt befasst sich mit zwei Kernzielen: <b>Mitarbeiterplanung</b> und
            <b>Analyse der Mitarbeiterbindung</b>. Es verwendet simulierte Daten, die typische Merkmale des
            Einzelhandels widerspiegeln. (Hinweis: Alle in diesem Projekt verwendeten Daten sind simuliert und nicht
            repr√§sentativ f√ºr reale Daten.)
        </h3>

        <h3><b>SCHRITTE 1: Verst√§ndnis der Industrie</b><br><br>
            <b>I. Mitarbeiterplanung:<br></b> Eine datengest√ºtzte Planung gew√§hrleistet eine ausreichende
            Personalausstattung, um den betrieblichen Anforderungen bei unterschiedlichen Arbeitsbelastungen gerecht zu
            werden, und ber√ºcksichtigt gleichzeitig die Pr√§ferenzen und Verf√ºgbarkeiten der Mitarbeiter. Dieser Ansatz
            maximiert die Produktivit√§t des Unternehmens, indem er sicherstellt, dass der richtige Mitarbeiter zur
            richtigen Zeit verf√ºgbar ist.
            <br><br>
            <b>II. Analyse der Mitarbeiterbindung:<br></b> Die Mitarbeiterbindung ist eine zentrale Herausforderung im
            Einzelhandel. Die Analyse der Mitarbeiterbindung hilft dabei, die wichtigsten Faktoren zu identifizieren,
            die zur Fluktuation beitragen, und unterst√ºtzt die Entwicklung gezielter Strategien, um die Fluktuation zu
            reduzieren und die Mitarbeiterbindung langfristig zu verbessern.
            <br><br>
            <b>Leistungskennzahlen (KPI):</b> in diesem Projekt geh√∂ren die Fluktuations- und Bindungsraten sowie die
            gesch√§tzten Kosten, die mit √úber- und Unterbesetzung verbunden sind. Eine hohe Fluktuation im Einzelhandel
            erh√∂ht nicht nur die Einstellungs- und Schulungskosten, sondern st√∂rt auch den Gesch√§ftsbetrieb und mindert
            die Servicequalit√§t. Das bedeutet, dass effektive Strategien zur Mitarbeiterbindung sich direkt auf die
            Rentabilit√§t auswirken k√∂nnen.
            <br><br>
            Durch die Optimierung der Dienstpl√§ne soll in diesem Projekt untersucht werden, ob es einen Zusammenhang
            zwischen der Pr√§ferenz f√ºr bestimmte Schichten und der Fluktuation gibt und ob bestimmte Funktionen oder
            Filialen einen unterschiedlichen Personalbedarf haben.
        </h3>

        <h3><b>SCHRITTE 2: Verst√§ndnis der Daten</b><br><br>
            Dieses Projekt basiert auf Daten, die zwischen 2015 und 2023 in acht Convenience-Stores gesammelt wurden.
            Vor der Implementierung datengesteuerter Planungsl√∂sungen muss sichergestellt werden, dass die verwendeten
            Daten f√ºr das jeweilige Gesch√§ftsproblem relevant sind.
            <br><br>
            In der Phase des Datenverst√§ndnisses liegt der Schwerpunkt auf der Identifizierung und Erfassung aller
            Aktivit√§ten, die mit dem Problem in Zusammenhang stehen. Dies dient als Grundlage f√ºr die Erstellung des
            endg√ºltigen Datensatzes aus den verf√ºgbaren Rohdaten. Zu den wichtigsten Aufgaben in diesem Schritt geh√∂ren
            die Datenerfassung, die erste Untersuchung und die Bewertung der Datenqualit√§t.
            <br><br>
            Das Projekt st√ºtzt sich auf die folgenden zwei Datenkategorien, die aus acht Convenience-Stores stammen.
            Diese beiden Elemente bilden die Grundlage sowohl f√ºr die Planungsoptimierung als auch f√ºr die
            Kundenbindungsanalyse:
            <br><br>
            <b>HINWEIS:</b> In diesem Projekt werde ich typische Datenqualit√§tsprobleme wie Anomalien oder fehlende
            Werte nicht ber√ºcksichtigen, da alle Daten speziell f√ºr Simulationszwecke generiert wurden.
        </h3>

        <img src="bilder/project_zwei1.png" alt="Project dataset 1">

        <h3>1. Mitarbeiterinformationen: Diese Attribute variieren je nach Mitarbeiter und umfassen die folgenden
            Datenpunkte:<br>+ ID nummer<br>+ Schichtverf√ºgbarkeit<br>+ Qualifikationen<br>+ √úberstunden (Verf√ºgbarkeit)
            <br>+ Schichtpr√§ferenz<br>+ Einstellungsdatum<br>+ Entlassungsdatum<br>+ Gemischtwarenladen nummer
            <br><br>
            <b>HINWEIS:</b> Mitarbeiterinformationen sind f√ºr die Analyse der Mitarbeiterbindung und f√ºr die Verwaltung
            der Pr√§ferenzen und Verf√ºgbarkeiten der Mitarbeiter bei der Dienstplanerstellung unerl√§sslich. Diese
            Informationen helfen uns dabei, w√∂chentliche Dienstpl√§ne zu erstellen, die den Anforderungen des Gesch√§fts
            gerecht werden und gleichzeitig die individuellen Pr√§ferenzen der Mitarbeiter ber√ºcksichtigen.
        </h3>

        <h3>2. Filialelemente: Diese Elemente unterliegen st√§ndigen Schwankungen und repr√§sentieren alle Vorg√§nge, die
            innerhalb der Filiale stattfinden. <br>+ Datum<br>+ Gemischtwarenladen nummer<br>+ Feiertag<br>+ Gro√üe
            Sonderaktionen<br>+ Kundenfrequenz<br>+ Beleggr√∂√üe<br>+ Produktverk√§ufe
            <br><br>
            <b>HINWEIS:</b> Die Filialelemente sind entscheidend f√ºr das Verst√§ndnis der betrieblichen Unterschiede
            zwischen den acht Convenience-Stores und daf√ºr, wie Faktoren wie die Nachfrage in den Filialen sich auf die
            Personalausstattung und die Mitarbeiterbindungsraten auswirken k√∂nnen. Es ist wichtig zu ber√ºcksichtigen,
            dass alle Filialen an sechs Tagen in der Woche mit zwei Schichten pro Tag betrieben werden.
            <br><br>
            Abschlie√üend m√∂chte ich noch anmerken, dass die Daten zwar synthetisch sind, aber so konzipiert sind, dass
            sie realistische Muster widerspiegeln, die in Workforce-Management-Projekten beobachtet werden, unter
            anderem Fluktuationstrends und filialspezifische Nachfrageschwankungen.
        </h3>

        <img src="bilder/project_zwei2.png" alt="Project dataset 2">

        <h3><b>SCHRITTE 3: Aufbereitung der Daten</b><br><br>
            Die Datenaufbereitung umfasst im Wesentlichen den Prozess der Anpassung der im vorherigen Schritt
            extrahierten Informationen und der Umwandlung dieser Daten, um sie leichter bearbeiten zu k√∂nnen und die
            Informationen √ºbersichtlicher anzuordnen, damit Aspekte der Informationen wie Variablennamen, Datentypen,
            fehlende Werte und sogar Datenverteilungen identifiziert werden k√∂nnen.
            <br><br>
            Datentypen spielen eine entscheidende Rolle bei der Datenaufbereitung und -exploration, da sie je nach dem
            angegebenen Format zur Durchf√ºhrung bestimmter Operationen verwendet werden. Im Fall des
            Mitarbeiter-Datenrahmens haben wir es mit einer Reihe von Variablen zu tun, die zun√§chst in einem falschen
            Datentyp eingelesen werden, wodurch die Variable falsch dargestellt wird und wir wichtige Aufgaben f√ºr die
            Datentransformation nicht ausf√ºhren k√∂nnen. Aus diesem Grund wandeln wir die Datenspalten in besser
            geeignete Datentypen um.
            <br><br><b>Ver√§nderte Datentypen:</b>
            <br>+ √úberstunden (JA/NEIN) --> (True/False)
            <br>+ Schichtpr√§ferenz (JA/NEIN) --> (True/False)
            <br>+ Einstellungsdatum (object) --> (datetime64[ns])
            <br>+ Entlassungsdatum (object) --> (datetime64[ns])
            <br>+ Gemischtwarenladen (int64) --> (object)
        </h3>

        <section class="sample_code">
            <b># Python CODE: Aufbereitung der Daten</b>
            <br><br>import numpy as np
            <br>import pandas as pd
            <br><br>staff_df = pd.read_csv("/.../databases/staff_elements.csv", encoding='latin1', header=0)
            <br><br>staff_df = staff_df.replace('k.A', np.nan)
            <br><br>staff_df[['√úberstunden', 'Schichtpr√§ferenz']] = staff_df[['√úberstunden', 'Schichtpr√§ferenz']].replace({'JA': 1, 'NEIN': 0}).astype('bool')
            <br><br>staff_df['Einstellungsdatum'] = pd.to_datetime(staff_df['Einstellungsdatum'], format='%d/%m/%Y')
            <br><br>staff_df['Entlassungsdatum'] = pd.to_datetime(staff_df['Entlassungsdatum'], format='%d/%m/%Y')
            <br><br>staff_df['Tage_zwischen'] = (staff_df['Entlassungsdatum'] - staff_df['Einstellungsdatum']).dt.days
            <br><br>staff_df['Gemischtwarenladen'] = staff_df['Gemischtwarenladen'].astype(str)
            <br><br><br>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Personal data types:
            <br>ID Nummer&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;object
            <br>Vorname&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;object
            <br>Nachname&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;object
            <br>Schichtverf√ºgbarkeit&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;object
            <br>Qualifikationen&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;object
            <br>√úberstunden&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;object --> bool
            <br>Schichtpr√§ferenz&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;object --> bool
            <br>Einstellungsdatum&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;object --> datetime64[ns]
            <br>Entlassungsdatum&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;object --> datetime64[ns]
            <br>Gemischtwarenladen&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int64&nbsp;&nbsp; --> object
            <br>Tage_zwischen&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;float64
            <br>dtype: object
        </section>

        <img src="bilder/project_zwei3.png" alt="Project Karte">

        <h3>Bevor wir zum n√§chsten Schritt √ºbergehen, betrachten wir zun√§chst die folgenden Aspekte der Daten, die die
            Strukturierung der Datenauswertung beeinflussen werden.
            <br>--> 8 verschiedene Filialen
            <br>--> 87 Monate
            <br>--> 3 Arten von Stellen
            <br>--> 2 Arten von Arbeitsschichten
            <br>--> 1500 Mitarbeiter-IDs mit Einstellungs- und K√ºndigungsdaten
        </h3>

        <h3><b>SCHRITT 4: Datenexploration und -visualisierung</b><br><br>
            Der erste Schritt der Datenanalyse beginnt nach der Datenaufbereitung, sobald der Datensatz bereinigt und
            strukturiert ist. Die Hauptziele der Datenauswertung sind: 1. Verstehen, was in einem Datensatz enthalten
            ist, 2. Seine Eigenschaften identifizieren, 3. M√∂gliche Beziehungen zwischen Datenelementen finden und 5.
            Anomalien oder Muster entdecken. All dies geschieht durch die Generierung von ‚ÄûMetadaten‚Äù.
            <br><br>
            Dies wird durch die Generierung und Auswertung von Metadaten erreicht, bei denen es sich um strukturierte
            Informationen handelt, die Daten beschreiben. Metadaten umfassen <b>beschreibende, strukturelle, referenzielle
            und statistische</b> Elemente, die dazu dienen, durch das Verst√§ndnis der Art der Informationen ein mentales
            Modell des Datensatzes zu erstellen.

            <br><br>In den meisten F√§llen hilft uns die deskriptive Analyse dabei, die Eigenschaften eines Datensatzes
            anhand von drei verschiedenen Messgr√∂√üen zu bestimmen::
            <br>1. Zentraler Tendenzwert (Durchschnitt, Median, Modus)
            <br>2. Variabilit√§t (Standardabweichung, Spannweite, Interquartilsabstand)
            <br>3. H√§ufigkeit der Verteilung
        </h3>

        <section class="sample_code">
            Python bietet die <b>describe()</b> Funktion f√ºr die wichtigsten Ma√üe der Zentralit√§t und sogar einige Ma√üe
            der Variabilit√§t, nachdem die folgenden Ma√üe angepasst werden k√∂nnen:
            <br><br>+ <b>Schiefe:</b> Messen des Grades der Asymmetrie in einer Verteilung. (Je n√§her an Null, desto
            symmetrischer die Verteilung.
            <br><br>+ <b>Kurtosis:</b> Messen der √Ñhnlichkeit mit einer Normalverteilung. (Je n√§her an 0, desto eher
            folgt die Verteilung einer Normalverteilung.
            <br><br>+ <b>Jarque-Bara test:</b> Ein Hypothesentest, der sowohl Schiefe als auch Kurtosis ber√ºcksichtigt,
            um die Hypothese zu √ºberpr√ºfen, dass die Daten aus einer Normalverteilung stammen.
            <br>count&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;23856.00 ---- 19808.00
            <br>mean&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;21.71 ---- 26.15
            <br>std&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;12.64 ---- 8.73
            <br>min&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.00 ---- 0.64
            <br>25%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;14.53 ---- 20.6
            <br>50%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;23.95 ---- 25.88
            <br>75%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;30.15 ---- 31.55
            <br>max&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;60.44 ---- 60.44
            <br>skew&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-0.35 ---- 0.20
            <br>kurt&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-0.54  ---- 0.12
            <br>jarque-bera (p-value) &nbsp;&nbsp;&nbsp;0.0000 ---- 0.0000
            <br>Name: Beleggr√∂√üe, dtype: float64
            <br><br> Ergebnisse belegen, dass die Verteilung der Beleggr√∂√üe einer Normalverteilung folgt.
        </section>

        <h3><b>TESTS F√úR NORMATIVE DATEN:</b><br>
            Eine Normalverteilung ist eine kontinuierliche Wahrscheinlichkeitsverteilung, die symmetrisch um ihren
            Mittelwert verl√§uft, wobei sich die meisten Beobachtungen um den zentralen Peak gruppieren und die
            Wahrscheinlichkeit der Werte symmetrisch abnimmt, je weiter sie sich vom Mittelwert entfernen. Dieses
            Verhalten erm√∂glicht aussagekr√§ftige Wahrscheinlichkeitssch√§tzungen und Vergleiche zwischen Datenpunkten.
            <br><br>
            Deskriptive Analysen zielen oft darauf ab, zu beurteilen, ob Daten einer normalen (Gaussian) Verteilung
            nahekommen. Auf diese Weise k√∂nnen Standardisierungstechniken angewendet werden, die es erm√∂glichen,
            Beobachtungen zu vergleichen und Wahrscheinlichkeiten √ºber verschiedene Populationen hinweg zu berechnen.
            Ohne Normalit√§t werden die meisten statistischen Tests und Modelle pl√∂tzlich ung√ºltig.
            <br><br>
            Die meisten statistischen Hypothesentests gehen davon aus, dass die Daten einer Glockenkurve folgen, was in
            den meisten analysierten Datenbanken nicht der Fall ist. Aus diesem Grund sind Transformationstechniken wie
            logarithmische, Quadratwurzel- oder Box-Cox-Transformationen entscheidend, um Daten so anzupassen, dass sie
            normativen Verteilungen entsprechen.
        </h3>

        <h3><b>HINWEIS:</b> Bei der Arbeit mit linearen Modellen wie LDA, Gau√üscher Naive Bayes, logistischer
            Regression, linearer Regression usw. sollten Sie zun√§chst die Datenverteilung messen und sicherstellen,
            dass alle im Modell verarbeiteten Daten einer Normalverteilung nahekommen, da alle Modelle explizit unter
            der Annahme berechnet werden, dass die Verteilung eine bivariate oder multivariate Normalverteilung ist.
            <br><br>
            Bei der Durchf√ºhrung einer explorativen Datenanalyse (besser bekannt als EDA) ist es wichtig, die im
            Datensatz vorhandenen Datentypen zu ber√ºcksichtigen. Variablen k√∂nnen numerisch (kontinuierlich/diskret)
            oder kategorial (ordinal/nominal) sein, und diese Unterscheidung wirkt sich darauf aus, wie jedes Merkmal
            analysiert wird.
            <br><br>
            Ein gutes Beispiel daf√ºr ist, dass kontinuierliche Variablen am besten durch statistische Verteilungen
            zusammengefasst werden, w√§hrend kategoriale Variablen H√§ufigkeitsz√§hlungen und Kontingenztafeln erfordern.
            Dies tr√§gt dazu bei, die richtige Auswahl visueller und statistischer Methoden in der sp√§teren
            Modellierungsphase sicherzustellen (was ich in den folgenden Abschnitten demonstrieren werde).
        </h3>

        <img src="bilder/project_zwei4.png" alt="Project Grafik 1">

        <h3><b>DATEN VISUALISIERUNG</b><br>
            Dank der Datenvisualisierung k√∂nnen viele statistische Annahmen schnell validiert werden, basierend darauf,
            wie sich die Daten in verschiedenen Diagrammen und Grafiken darstellen. Visualisierungsmethoden wie
            Histogramme, Boxplots und Streudiagramme helfen dabei, die Form, Streuung und Muster in den Daten zu
            verstehen.
            <br><br>
            Beispielsweise zeigen fr√ºhere Balkendiagramme die unterschiedlichen Verteilungen von Ladenums√§tzen,
            Kundenfrequenz, Rechnungsbetr√§gen und Mitarbeiterbindungsdauer. Diese visuellen Hinweise erleichtern das
            Verst√§ndnis der Leistungskennzahlen und helfen, Anomalien fr√ºhzeitig zu erkennen.
        </h3>

        <img src="bilder/project_zwei5.png" alt="Project Grafik 2">

        <h3>Bei der Analyse kategorialer Daten ist es wichtig, auf Klassenungleichgewichte zu achten. Wenn eine Klasse
            √ºber- oder unterrepr√§sentiert ist, werden Vorhersagemodelle oft verzerrt, was die Genauigkeit und
            Interpretierbarkeit beeintr√§chtigt. In dem Fall weist der Mitarbeiterdatensatz relativ ausgewogene
            Stichprobengr√∂√üen f√ºr die meisten kategorialen Merkmale auf, was f√ºr faire Vergleiche und ein robustes
            Modelltraining wichtig ist.
            <br><br>
            Im Fall der Personaldaten k√∂nnen wir die Stichprobengr√∂√üen f√ºr die wichtigsten kategorialen Daten
            identifizieren, die die Bindung beeinflussen. In diesem Fall sind die Stichprobengr√∂√üen f√ºr fast alle
            kategorialen Daten nahezu gleich. Das ist wichtig, da gleiche Stichprobengr√∂√üen dazu beitragen,
            sicherzustellen, dass beobachtete Unterschiede zwischen den Kategorien nicht einfach auf Zufall
            zur√ºckzuf√ºhren sind. So l√§sst sich leichter feststellen, ob beobachtete Unterschiede statistisch
            signifikant sind oder einfach auf die Zuf√§lligkeit des Stichprobenverfahrens zur√ºckzuf√ºhren sind.
        </h3>

        <div id="heatmap">
            <py-script>
                import pandas as pd
                import seaborn as sns
                import matplotlib.pyplot as plt
                from pyscript import display

                df = pd.read_csv("corr_matrix_v2.csv", header=0, index_col=0)

                fig, ax = plt.subplots()
                sns.heatmap(df, annot=False, cmap="Oranges", ax=ax)
                ax.set_title("Pearson Korrelationsanalyse (Mitarbeiter-Data)")
                display(fig, target="heatmap")
            </py-script>
        </div>

        <h3>Ein weiteres wichtiges Instrument bei der Datenauswertung ist die Korrelationsanalyse, beispielsweise die
            Pearson-Korrelation, die die St√§rke und Richtung linearer Beziehungen zwischen Variablenpaaren
            quantifiziert. Das Verst√§ndnis von Korrelationen ist f√ºr die pr√§diktive Modellierung unerl√§sslich, um
            Multikollinearit√§t zu vermeiden und die einflussreichsten Pr√§diktoren zu identifizieren.
            <br><br>
            Im Falle der <b>Mitarbeiterbindungsanalyse</b> ist eine der wichtigsten Variablen die Besch√§ftigungsdauer,
            gemessen als Zeit zwischen Einstellungs- und K√ºndigungsdatum. Das Verst√§ndnis, welche Variablen mit
            l√§ngeren oder k√ºrzeren Besch√§ftigungszeiten korrelieren, liefert umsetzbare Erkenntnisse √ºber die Dynamik
            der Belegschaft und k√∂nnte Managern sogar helfen, zu verstehen, welche Faktoren in den letzten 87 Monaten
            der Datenerfassung den gr√∂√üten Einfluss auf die Mitarbeiterbindung hatten.
            <br><br>
            Gem√§√ü der Pearson-Korrelationsmatrix sind die relevantesten Variablen f√ºr die Mitarbeiterbindung:
            <br><b>Schichtpr√§ferenz &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;55.5059%</b>
            <br><b>(Qualifikationen) Reinigungskraft &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-41.5935%</b>
            <br><b>(Qualifikationen) Verk√§ufer &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;21.7596%</b>
        </h3>

        <h3>Es ist auch sinnvoll, die Multikollinearit√§t zwischen unabh√§ngigen Variablen zu bewerten. Hohe
            Korrelationen zwischen Pr√§diktoren k√∂nnen die Varianz in Modellsch√§tzungen erh√∂hen und den individuellen
            Einfluss jeder Variablen verschleiern. Bei starker Multikollinearit√§t ist es wichtig, redundante Merkmale
            vor der Modellentwicklung zu filtern.
            <br><br>
            F√ºr die <b>Retentionsanalyse problem</b> m√ºssen wir ein Vorhersagemodell entwickeln und trainieren, das die
            Faktoren ber√ºcksichtigt, die zur Mitarbeiterfluktuation beitragen. Bevor eine Vorhersagemodellierung
            durchgef√ºhrt werden kann, muss auch die Saisonalit√§t getestet werden, d. h. wiederkehrende Muster, die auf
            bestimmten Zeitintervallen basieren. Die Saisonalit√§t kann in einigen Bereichen einen erheblichen Einfluss
            auf den Personalbedarf haben.
        </h3>

        <img src="bilder/project_zwei6.png" alt="Project Grafik 3">

        <h3>Saisonalit√§tstests suchen nach periodischen Schwankungen innerhalb historischer Daten oder Zyklen, die
            regelm√§√üig zu einer bestimmten Jahreszeit auftreten. Eine Jahreszeit kann mit einer Kalenderjahreszeit
            (Sommer oder Winter) in Verbindung stehen oder sich auf eine Ferienzeit beziehen.
            <br><br>
            Durch den Vergleich zweier Arten historischer Daten ‚Äì Ladenums√§tze und Besch√§ftigungsdauer ‚Äì stellen wir
            fest, dass die Ums√§tze √ºber einen Zeitraum von 87 Monaten deutliche saisonale Spitzen aufweisen. Die
            Besch√§ftigungsdauer zeigt jedoch keine solche Periodizit√§t. Dies deutet darauf hin, dass f√ºr der Problem
            der Mitarbeiterbindung Saisonaltests nicht anwendbar sind, da die Einstellungs- und Fluktuationsmuster
            keinen saisonalen Trends folgen.
        </h3>

        <img src="bilder/project_zwei7.png" alt="Project Grafik 4">

        <h3><b>SCHRITTE 5: Entwicklung von Merkmalen</b><br><br>
            Um mit dem n√§chsten Schritt fortzufahren, m√ºssen wir die Daten f√ºr die weitere Analyse aufbereiten. Dazu
            k√∂nnen Aufgaben wie die Normalisierung oder Standardisierung von Variablen, die Erstellung neuer Variablen
            auf der Grundlage bestehender Variablen oder die Reduzierung der Dimensionalit√§t der Daten geh√∂ren. Auf
            diese Weise k√∂nnen wir die Leistung der Modelle erheblich verbessern.
            <br><br>
            Ein weiterer wesentlicher Aspekt des Feature Engineering ist die Umwandlung kategorialer Variablen in
            numerische Darstellungen. Dies geschieht in der Regel durch die Erstellung von Dummy-Variablen, die es uns
            erm√∂glichen, den Einfluss jeder Kategorie auf die Antwortvariable zu erfassen, indem wir ihre jeweiligen
            Koeffizienten in einem Regressionsmodell vergleichen.
            <br><br>
            F√ºr das Regressionsmodell zur Fluktuationsanalyse verwenden wir Daten auf Mitarbeiterebene mit
            Dummy-Variablen, die aus kategorialen Spalten wie Qualifikationen, Schichtpr√§ferenz, Schichtverf√ºgbarkeit
            und √úberstundenverf√ºgbarkeit generiert wurden. Diese transformierten Variablen erm√∂glichen es uns, zu
            quantifizieren, wie verschiedene Attribute die Besch√§ftigungsdauer oder die Wahrscheinlichkeit einer
            Fluktuation beeinflussen.
        </h3>

        <section class="sample_code">
            Bei einem -<b>MITARBEITERPLANUNGSPROBLEM</b>- ist es wichtig, die Verf√ºgbarkeit der Mitarbeiter auf einer
            sehr detaillierten Ebene zu ber√ºcksichtigen. In dem Modell bedeutet dies, dass nach Convenience-Store,
            Schichttyp, Rollen und bestimmten Daten unterschieden werden muss.
            <br><br>
            Um die Besch√§ftigungsdauer eines Mitarbeiters in einen f√ºr das Planungsmodell nutzbaren Datumsbereich
            umzuwandeln, m√ºssen wir einen vollst√§ndigen Zeitplan f√ºr die Verf√ºgbarkeit extrahieren. Die Verf√ºgbarkeit
            jedes Mitarbeiters sollte als t√§gliche Abfolge zwischen seinem Start- und Enddatum dargestellt werden,
            damit der Planungsalgorithmus genau wei√ü, wann jeder Mitarbeiter f√ºr Schichten eingeteilt werden kann.
            <br><br><br>
            <b># Python CODE: ENTWICKLUNG VON MERKMALEN
            <br>Diese Codezeilen generieren Hunderte von Spalten mit Bin√§rwerten zwischen den Daten 2015 und 2023, um
                die Verf√ºgbarkeit der Mitarbeiter w√§hrend dieser Zeitr√§ume darzustellen.</b>
            <br>staff_model['date_range'] = staff_model.apply(lambda row: pd.date_range(start=row['Einstellungsdatum'],
                                                                  end=row['Entlassungsdatum'], freq='D'), axis=1)
            <br>datumsbereich = pd.date_range(start="01/01/2015", end="31/03/2023", freq='D')
            <br>for date in datumsbereich:
            <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;staff_model[date.strftime('%d.%m.%Y')] = staff_model['date_range'].apply(lambda x: 1 if date in x else 0)
            <br>staff_model.drop('date_range', axis=1, inplace=True)
            <br><br><b>Die folgenden Codezeilen l√∂schen alle Daten, die Feiertage und Sonntage darstellen, an denen die
            Gesch√§fte geschlossen sein sollen und kein Personal ben√∂tigt wird.</b>
            <br>date_filter = store_retention[store_retention.Datum.dt.weekday == 6]
            <br>date_filter = date_filter[date_filter["Feiertag"] != 1]
            <br>date_list = list(date_filter["Datum"])
            <br>date_list_str = [date.strftime('%Y-%m-%d %H:%M:%S') for date in date_list]
            <br>date_list = [datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S').strftime('%d.%m.%Y') for date in date_list_str]
        </section>

        <h3>Zeitbasierte Merkmale sind sowohl im Retentions- als auch im Planungsmodell von entscheidender Bedeutung.
            Sie k√∂nnen dabei helfen, Muster zu erkennen, z. B. dass Mitarbeiter nach einer bestimmten Dauer eher
            k√ºndigen oder dass bestimmte Schichten an bestimmten Wochentagen unterbesetzt sind.
            <br><br>
            Die Identifizierung anderer Arten von Wechselwirkungen zwischen kategorialen und numerischen Variablen kann
            die Vorhersagekraft des Bindungsmodells erh√∂hen. Beispielsweise kann die Kombination von Schichtpr√§ferenzen
            mit geleisteten √úberstunden wichtige Dynamiken in Bezug auf Stress oder Burnout bei Mitarbeitern aufzeigen,
            die sich direkt auf die Fluktuationsrate auswirken. Diese Wechselwirkungen k√∂nnen manuell konstruiert oder
            w√§hrend des Modelltrainings √ºber baumbasierte Modelle erkannt werden.
        </h3>

        <img src="bilder/project_zwei8.png" alt="Project dataset 3">

        <h3><b>SCHRITTE 6: Aufbau von Modellen</b><br><br>
            Das Hauptziel des Projekts dreht sich um die Modellierung und das Training. Im Rahmen dieses Projekts
            werden wir zwei verschiedene Arten von Modellen entwickeln: ein Optimierungsmodell f√ºr die
            Mitarbeiterplanung und ein logistisches Regressionsmodell f√ºr die Analyse der Mitarbeiterbindung.
            <br><br>
            F√ºr das Problem der <b>Mitarbeiterplanung</b> verwenden wir die PuLP-Bibliothek, ein Python-basiertes
            Toolkit f√ºr lineare Programmierung, das sich auf die Definition von Entscheidungsvariablen, Einschr√§nkungen
            und einer Zielfunktion f√ºr ein Optimierungsmodell konzentriert. Das Optimierungsmodell von PuLP bietet
            ausreichend Flexibilit√§t, um komplexe Probleme der Personalzuweisung im Rahmen der linearen Programmierung
            zu l√∂sen.
            <br><br>
            Die lineare Programmierung eignet sich besonders f√ºr die Optimierung der Mitarbeiterplanung, da sie
            quantitative Entscheidungen erm√∂glicht und gleichzeitig sicherstellt, dass wichtige betriebliche und
            personelle Einschr√§nkungen ber√ºcksichtigt werden, insbesondere durch die Verwendung der bin√§ren
            ganzzahligen linearen Programmierung, bei der Entscheidungsvariablen die Werte 0 oder 1 annehmen, um eine
            Zuweisung oder Nichtzuweisung anzuzeigen.
        </h3>

        <h3>Die lineare Programmierung ist eine mathematische Modellierungstechnik, die eine Reihe von
            Eingabebeschr√§nkungen innerhalb der quantitativen Entscheidungsfindung bei der Mitarbeiterplanung
            ber√ºcksichtigt. Im Fall dieses Problems der Mitarbeiterplanung ber√ºcksichtigen wir die folgenden
            Einschr√§nkungen:<br>1. Schichtpr√§ferenzen<br>2. Arten von Stellen<br>3. Maximale Anzahl
            aufeinanderfolgender Arbeitstage des Mitarbeiter.
            <br><br>
            Die √úbersetzung der Entscheidungsvariablen, die wir durch die Schritte ‚ÄûDatenverst√§ndnis‚Äú,
            ‚ÄûDatenaufbereitung‚Äú, ‚ÄûDatenexploration‚Äú und ‚ÄûFeature Engineering‚Äú erhalten haben, ergibt die folgenden
            Bezeichnungen:<br>
            <code>x<sub>e,s,d</sub> ‚àà {0, 1}</code> sind die bin√§re Entscheidungsvariable<br>
            <code>e ‚àà E</code>: Menge der Mitarbeiter<br>
            <code>s ‚àà S</code>: Menge der Schichttypen (z.B. ‚ÄúMorgenschicht‚Äù, ‚ÄúNachmittagsschicht‚Äù)<br>
            <code>d ‚àà D</code>: Menge der Daten
            <br><br>
            Die Zielfunktion des Mitarbeiterplanungsmodells ist darauf ausgelegt, die Gesamtpr√§ferenzzufriedenheit der
            Belegschaft zu maximieren. Jeder Mitarbeiter hat eine erkl√§rte oder abgeleitete Schichtpr√§ferenz ‚Äì in der
            Regel zwischen ‚ÄûMorgenschicht‚Äù und ‚ÄûNachmittagsschicht‚Äù. Diese Pr√§ferenzen werden als bin√§re Werte kodiert,
            wobei der Wert 1 bedeutet, dass ein Mitarbeiter f√ºr diese Schicht verf√ºgbar oder bereit ist, sie zu
            arbeiten, und 0 das Gegenteil.
        </h3>

        <section class="sample_code">
            <b># Python CODE: Aufbau von Modellen (Modell zur Optimierung der Mitarbeiterplanung)</b>
            <br>opt_prob = plp.LpProblem("Employee Scheduling", plp.LpMinimize)
            <br>personal = staff_df['ID Nummer'].tolist()
            <br>schichtverfugbarkeit = staff_df['Schichtverf√ºgbarkeit'].unique().tolist()
            <br>qualifikationen = staff_df['Qualifikationen'].unique().tolist()
            <br>datum = datumsbereich.strftime('%d.%m.%Y').tolist()
            <br>datum = [x for x in datum if x not in date_list]
            <br><br>x = plp.LpVariable.dicts("x", [(a, b, c) for a in personal for b in schichtverfugbarkeit for c in
            datum], cat='Binary')
            <br>opt_prob += plp.lpSum([x[(a, b, c)] for a in personal for b in schichtverfugbarkeit for c in datum])
            <br>for c in datum:
            <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for b in schichtverfugbarkeit:
            <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;opt_prob += plp.lpSum([x[(a, b, c)] for a in personal]) >= staff_df[staff_df[
            'Schichtverf√ºgbarkeit'] == b][d].sum()
            <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for d in qualifikationen:
            <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;opt_prob += plp.lpSum([x[(a, c, c)] for a in personal if staff_df.loc[staff_df
            ['ID Nummer'] == a, 'Qualifikationen'].item() == d]) >= \
                        staff_df[(staff_df['Schichtverf√ºgbarkeit'] == b) & (staff_df[c] == 1) &
                             (staff_df['Qualifikationen'] == d)][c].sum()
            <br><br>for a in personal:
            <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for i in range(len(datum) - 4):
            <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;opt_prob += plp.lpSum([x[(a, b, datum[j])] for j in range(i, i + 5) for b in
            schichtverfugbarkeit]) <= 5
            <br>opt_prob.solve()
        </section>

        <h3>Das Modell summiert dann die Anzahl der Zuweisungen, die diesen Pr√§ferenzen √ºber alle Mitarbeiter,
            Schichten und Tage hinweg entsprechen. Dies f√ºhrt zu einer Optimierungsfunktion, die nicht nur die
            erforderlichen Positionen besetzt, sondern auch versucht, die Pr√§ferenzen der Mitarbeiter so weit wie
            m√∂glich zu ber√ºcksichtigen, was zu einer h√∂heren Zufriedenheit und m√∂glicherweise zu einer besseren
            Mitarbeiterbindung beitragen kann.
            <br><br>
            Das Optimierungsmodell maximiert die Gesamtzufriedenheit mit den Schichtpr√§ferenzen und gibt Mitarbeitern,
            die in ihren bevorzugten Schichten arbeiten, Vorrang. Mathematisch l√§sst sich dies wie folgt darstellen:
            <br><br>
            <code>Maximize Z = ‚àë(e ‚àà E) ‚àë(s ‚àà S) ‚àë(d ‚àà D) p<sub>e,s</sub> √ó x<sub>e,s,d</sub></code>
            <br>Wenn <code>p<sub>e,s</sub> ‚àà {0,1}</code>: preference score = 1 wenn Mitarbeiter <code>e</code> eine
            Pr√§ferenz f√ºr den Schicht hat oder nicht<code>s</code>, Anderfalls 0.<br><br>
            <strong>Einschr√§nkung f√ºr eine Schicht pro Tag:</strong><br>
            <code>‚àë(s ‚àà S) x<sub>e,s,d</sub> ‚â§ 1 ‚àÄ e ‚àà E, ‚àÄ d ‚àà D</code>
            <br><br>
            <strong>Einschr√§nkung f√ºr maximal 5 aufeinanderfolgende Arbeitstage Einschr√§nkung</strong><br>
            <code>‚àë(i=0 to 5) ‚àë(s ‚àà S) x<sub>e,s,d<sub>i</sub></sub> ‚â§ 5</code> for any 6-day window
            <br><br>
            <strong>Einschr√§nkung f√ºr qualifiziertes Personal</strong><br>
            <code>‚àë(e ‚àà E<sub>q</sub>) x<sub>e,s,d</sub> ‚â• 1</code> if E<sub>q</sub> exists for shift s on day d
            <br><br>
            <strong>Domain Constraints</strong><br>
            <code>x<sub>e,s,d</sub> ‚àà {0, 1}</code>
        </h3>

        <video id="video" controls autoplay loop muted>
            <source src="videos/project_zwei.mp4" type="video/mp4">
        </video>

        <h3>Das mathematische Modell ber√ºcksichtigt die folgenden Einschr√§nkungen:<br>
            <b> -> Einschr√§nkung 1: Eine Schicht pro Tag</b><br>
            Um Gerechtigkeit und Praktikabilit√§t zu gew√§hrleisten, garantiert die erste Einschr√§nkung, dass kein
            Mitarbeiter mehr als einer Schicht pro Tag zugewiesen wird. Dies verhindert √úberlastung und
            Terminkonflikte. F√ºr jeden Mitarbeiter und jeden Tag √ºberpr√ºft das Modell alle m√∂glichen Schichten und
            stellt sicher, dass die Summe der Zuweisungsvariablen nicht gr√∂√üer als eins ist.
            <br><br>
            <b> -> Einschr√§nkung 2: Maximal 5 aufeinanderfolgende Arbeitstage</b><br>
            Die zweite Einschr√§nkung dient dem Wohlbefinden der Mitarbeiter, indem sie die Anzahl der
            aufeinanderfolgenden Tage begrenzt, an denen ein Mitarbeiter zur Arbeit eingeteilt werden kann. Dadurch
            wird verhindert, dass eine Sechstagewoche entsteht.
            <br><br>
            <b> -> Einschr√§nkung 3: Anforderung an qualifizierte Mitarbeiter</b><br>
            Diese Einschr√§nkung stellt sicher, dass jede Schicht an jedem Tag mit mindestens einem Mitarbeiter besetzt
            ist, der √ºber die erforderlichen Qualifikationen verf√ºgt. Beispielsweise k√∂nnen bestimmte Schichten eine
            ‚ÄûReinigungskraft‚Äù, eine ‚ÄûAushilfe‚Äù oder einen ‚ÄûVerk√§ufer‚Äù erfordern. Das Modell √ºberpr√ºft f√ºr jede
            Schicht-Tag-Kombination, ob mindestens ein Mitarbeiter mit der erforderlichen Qualifikation verf√ºgbar ist,
            und weist ihn entsprechend zu.
            <br><br>
            <b>HINWEIS:</b> Wenn kein qualifizierter Mitarbeiter verf√ºgbar ist, wird die Einschr√§nkung automatisch
            √ºbersprungen, um eine Unm√∂glichkeit zu vermeiden. Diese selektive Durchsetzung garantiert die
            Betriebskontinuit√§t, ohne die L√∂sbarkeit des Modells zu beeintr√§chtigen.
        </h3>

        <h3>Nachdem das Modell zur Mitarbeiterplanung nun ohne Probleme l√§uft, ist es an der Zeit, mit dem logistischen
            Regressionsmodell f√ºr die <b>Analyse der Mitarbeiterbindung</b> zu beginnen. Das Ziel dieses Modells ist
            es, Muster in den Merkmalen der Mitarbeiter aufzudecken, die mit einer k√ºrzeren oder l√§ngeren
            Betriebszugeh√∂rigkeit korrelieren, um dem Management fundierte Entscheidungen √ºber Einstellungs-,
            Schulungs- und Planungsrichtlinien zu erm√∂glichen. Die logistische Regression eignet sich besonders gut f√ºr
            diese Aufgabe, da sie anhand einer Kombination von Eingabevariablen die Wahrscheinlichkeit absch√§tzen kann,
            mit der ein Mitarbeiter in ein bin√§res Ergebnis f√§llt ‚Äì langfristig im Unternehmen verbleibt oder nicht.
            <br><br>
            Das logistische Regressionsmodell sch√§tzt die Wahrscheinlichkeit, mit der ein Mitarbeiter das Unternehmen
            verl√§sst, anhand der Werte der unabh√§ngigen Variablen. Das Modell liefert auch Informationen √ºber die
            St√§rke und Richtung der Beziehung zwischen jeder unabh√§ngigen Variablen und der Mitarbeiterbindung.
            <br><br>
            Das logistische Regressionsmodell basiert auf einer bin√§ren Antwortvariablen namens ‚Äûresponse‚Äù, die angibt,
            ob ein Mitarbeiter weniger als die durchschnittliche Besch√§ftigungsdauer aller Mitarbeiter im Unternehmen
            geblieben ist. Liegt die Gesamtzahl der Tage zwischen Einstellung und K√ºndigung (Tage_zwischen) unter dem
            Mittelwert des Datensatzes, wird die Antwort auf 1 gesetzt, andernfalls auf 0.
            <br><br>
            Diese bin√§re Kodierung erm√∂glicht es dem Modell, die Mitarbeiter in zwei Gruppen einzuteilen, und
            erm√∂glicht es dem logistischen Regressionsalgorithmus, Odds Ratios f√ºr jede Pr√§diktorvariable zu berechnen,
            die die Wahrscheinlichkeit einer k√ºrzeren Betriebszugeh√∂rigkeit darstellen.
        </h3>

        <section class="sample_code">
            <b># Python CODE: AUFBAU VON MODELLEN (Mitarbeiterbindung Logistik-Regressionsmodell)</b>
            <br>import statsmodels.api as sm
            <br>import pandas as pd
            <br><br>dumm_eins = pd.get_dummies(staff_df["Schichtverf√ºgbarkeit"], prefix="Schichtverf√ºgbarkeit")
            <br>dumm_zwei = pd.get_dummies(staff_df["Qualifikationen"], prefix="Qualifikationen")
            <br>dumm_drei = pd.get_dummies(staff_df["Gemischtwarenladen"], prefix="Gemischtwarenladen")
            <br><br>df_logit = pd.concat([staff_df, dumm_eins, dumm_zwei, dumm_drei], axis=1)
            <br><br>predictors = ["√úberstunden", "Schichtpr√§ferenz", "Schichtverf√ºgbarkeit_Morgenschicht",
              "Schichtverf√ºgbarkeit_Nachmittagsschicht", "Qualifikationen_Aushilfe", "Qualifikationen_Reinigungskraft",
              "Qualifikationen_Verk√§ufer", "Gemischtwarenladen_1", "Gemischtwarenladen_2", "Gemischtwarenladen_3",
              "Gemischtwarenladen_4", "Gemischtwarenladen_5", "Gemischtwarenladen_6", "Gemischtwarenladen_7",
              "Gemischtwarenladen_8"]
            <br><br>mean_resp = df_logit["Tage_zwischen"].mean()
            <br>df_logit["response"] = (df_logit["Tage_zwischen"] < mean_resp).astype(int)
            <br>response = ["response"]
            <br><br>X_train, X_test, y_train, y_test = train_test_split(df_logit[predictors], df_logit[response], train_size=0.8,
                                                    random_state=0)
            <br>model = sm.Logit(y_train, X_train).fit()
            <br>y_pred = model.predict(X_test)
            <br>y_pred = np.round(y_pred)
            <br><br>accuracy = accuracy_score(y_test, y_pred)
            <br>precision = precision_score(y_test, y_pred)
            <br>recall = recall_score(y_test, y_pred)
            <br>f1 = f1_score(y_test, y_pred)
        </section>

        <h3><b>Pr√§diktorvariable: √úberstunden</b><br>
            Eine der einflussreichsten Merkmale ist ‚Äû√úberstunden‚Äú, die angibt, ob der Mitarbeiter bereit ist,
            √úberstunden zu leisten. Die Einbeziehung dieser Variable hilft dabei, ihre tats√§chliche Rolle im
            Fluktuationsverhalten aufzudecken.
            <br><br>
            <b>Pr√§diktorvariable: Schichtpr√§ferenz</b><br>
            Diese bin√§re Variable gibt an, ob ein Mitarbeiter flexibel ist, was die Arbeit in verschiedenen
            Schichttypen angeht. Diese Variable ist entscheidend f√ºr die Bewertung, ob die Vereinbarkeit der
            Arbeitszeiten Einfluss auf die Mitarbeiterbindung hat.
            <br><br>
            <b>Pr√§diktorvariable: Schichtverf√ºgbarkeit, Qualifikationen, and Gemischtwarenladen </b><br>
            Weitere Pr√§diktoren sind One-Hot-codierte Darstellungen der Schichtverf√ºgbarkeit, der Qualifikationsart und
            des Standortes jedes Mitarbeiters. Diese Merkmale erfassen feste pers√∂nliche Eigenschaften und kontextuelle
            Faktoren, die sich unterschiedlich auf die Mitarbeiterbindung auswirken k√∂nnen. Beispielsweise k√∂nnten
            Mitarbeiter in gesch√§ftigeren Filialen oder mit einer bestimmten Art von Funktion eher dazu neigen,
            fr√ºhzeitig zu k√ºndigen.
        </h3>

        <h3>Die statistische Modellierung erfolgt mit der Python-Bibliothek statsmodels, die eine robuste und
            transparente Schnittstelle f√ºr die Anpassung generalisierter linearer Modelle, einschlie√ülich logistischer
            Regression, bietet. Die Funktion Logit() aus statsmodels.api wird zum Aufbau des Modells verwendet, und
            .fit() wird aufgerufen, um die Koeffizienten mit Hilfe der Maximum-Likelihood-Sch√§tzung zu sch√§tzen.
            Statsmodels erstellt eine detaillierte Zusammenfassung, die p-Werte, Konfidenzintervalle, Odds Ratios,
            Standardfehler und Wald-Teststatistiken enth√§lt.
            <br><br>
            Diese Ausgabe ist von unsch√§tzbarem Wert, um zu verstehen, welche Variablen einen signifikanten Einfluss
            auf die Mitarbeiterbindung haben und wie stark diese Effekte sind, √ºber einen einfachen Korrelationstest
            hinaus. Die Ergebnisse unterst√ºtzen auch die Entscheidungsfindung des Managements, indem sie
            Modellkoeffizienten in f√ºr Menschen lesbare Erkenntnisse √ºbersetzen. Zur Leistungsvalidierung werden
            zus√§tzliche Bewertungsmetriken wie Genauigkeit, Pr√§zision, Recall und F1-Score mit sklearn berechnet, um
            sicherzustellen, dass das Modell nicht nur statistisch, sondern auch in Bezug auf die Vorhersagegenauigkeit
            gut funktioniert.
            <br><br>
            <code>Logit()</code> definiert das logistische Regressionsmodell
            <br>
            <code>.fit()</code> sch√§tzt die Koeffizienten mittels Maximum Likelihood
            <br>
            <code>.summary()</code> liefert einen vollst√§ndigen statistischen Bericht, einschlie√ülich:
        </h3>



        <h3><b>SCHRITTE 7: Modellbewertung und -vergleich</b><br><br>
            Dank der Vorbereitung und Transformation der Daten in den vergangenen Schritten konnten wir durch den
            Prozess der <b>Modellbewertung</b> die folgenden Leistungskennzahlen f√ºr jedes Modell erhalten:
            <br><br><b>Optimierungsmodell:</b>
            <br>Anhand der Ergebnisse des Optimierungsmodells <b>(Status: Optimal)</b> k√∂nnen wir sehen, dass die
            Anpassung der Zeitpl√§ne innerhalb der verf√ºgbaren Ressourcen m√∂glich ist, wenn der Personalbedarf minimal
            ist (1 f√ºr jede Rolle).
            <br><br>
            Das <b>Optimierungsmodell</b> ist f√ºr die Verarbeitung von 502.843 eindeutigen Einschr√§nkungen
            (einschlie√ülich Einschr√§nkungen hinsichtlich der Schichtdauer) ausgelegt und verf√ºgt √ºber bis zu 970.280
            Entscheidungsvariablen (ganzzahlige Auswahlm√∂glichkeiten), wobei jede Variable angibt, ob ein Mitarbeiter
            einer bestimmten Schicht an einem bestimmten Datum zugewiesen ist, sowie √ºber bis zu 6.658.926 Elemente.
            <br><br>
            In diesem Fall ist das Mitarbeiterplanungsmodell in der Lage, zu verwalten, welche Mitarbeiter f√ºr jeden
            Tag und jede Schicht in jedem Gesch√§ft verf√ºgbar sind, und gleichzeitig sicherzustellen, dass die
            Einschr√§nkungen eingehalten werden.
        </h3>

        <h3>Diese Ergebnisse belegen, dass die Anzahl der w√§hrend jedes Zeitraums
            verf√ºgbaren Mitarbeiter ausreicht, um den Betrieb aller Gesch√§fte innerhalb der Stadt f√ºr insgesamt 87
            Monate (ohne Feiertage und Sonntage) aufrechtzuerhalten.
            <br><br>
            <b>LOGISTIC REGRESSION MODEL:</b>
            Wie bereits erw√§hnt, erm√∂glicht uns das logistische Regressionsmodell, die Variablen zu identifizieren, die
            den gr√∂√üten Einfluss auf die Mitarbeiterbindung haben. Anstatt einfach nur zu klassifizieren, ob ein
            Mitarbeiter innerhalb eines bestimmten Zeitraums das Unternehmen verlassen wird, sch√§tzt das Modell die
            Wahrscheinlichkeit der Fluktuation auf der Grundlage mehrerer Merkmale.
            <br><br>
            Anhand der Ergebnisse des logistischen Regressionsmodells k√∂nnen wir ermitteln, welche Variablen den
            gr√∂√üten Einfluss auf die Mitarbeiterbindung haben, da wir nicht einfach vorhersagen, ob ein Mitarbeiter das
            Gesch√§ft innerhalb eines bestimmten Zeitraums verlassen wird, sondern die Wahrscheinlichkeit sch√§tzen, dass
            er das Unternehmen verlassen wird.
            <br><br>
            Die Ausgabe eines logistischen Regressionsmodells umfasst eine Zusammenfassung der Modellkoeffizienten und
            andere Statistiken, die zur Bewertung der Modellleistung und zur Interpretation der Ergebnisse verwendet
            werden k√∂nnen. Zwei der wichtigsten Kennzahlen sind die Regressionskoeffizienten (coef) und die zugeh√∂rigen
            p-Werte (P>|z|).
        </h3>

        <img src="bilder/project_zwei9.png" alt="Project screenshot">

        <h3>Ein positiver Koeffizient zeigt an, dass ein Anstieg der entsprechenden Pr√§diktorvariable die
            logarithmische Wahrscheinlichkeit eines vorzeitigen Ausscheidens des Mitarbeiters erh√∂ht, w√§hrend ein
            negativer Koeffizient auf einen R√ºckgang dieser Wahrscheinlichkeit hindeutet. In unserem Modell weisen
            Variablen wie ‚ÄûSchichtpr√§ferenz‚Äú und ‚Äû√úberstunden‚Äú eine starke negative Korrelation mit der
            Mitarbeiterfluktuation auf, was bedeutet, dass sie die Wahrscheinlichkeit eines vorzeitigen Austritts
            verringern.
            <br><br>
            Ebenso bedeutet ein positiver Koeffizient f√ºr ‚ÄûQualifikationen_Reinigungskraft‚Äú, dass Besch√§ftigte mit
            Reinigungsaufgaben eher bereit sind, vorzeitig zu gehen. Der mit jedem Koeffizienten verbundene p-Wert
            misst die statistische Signifikanz. Kleinere p-Werte deuten darauf hin, dass die Variable einen bedeutenden
            Einfluss auf die Antwortvariable hat. In unserem Fall weisen einige Variablen - wie ‚ÄûSchichtverf√ºgbarkeit‚Äú
            - keine statistische Signifikanz auf, was darauf hindeutet, dass sie m√∂glicherweise nur einen begrenzten
            Einfluss auf die Ergebnisse der Mitarbeiterbindung haben.
        </h3>

        <section class="sample_code">
            <b># Python Output f√ºr die Optimization modell:</b>
            <br>Welcome to the CBC MILP Solver
            <br>Version: 2.10.3
            <br>Build Date: Dec 15 2019
            <br>Result - Optimal solution found
            <br>End time:  996.1563172340393
            <br>Status: Optimal
            <br>Total Cost = 33263.0
            <br><br><br>
            <b># Python Output for Regression model:</b>
            <br>Optimization terminated successfully.
            <br>Current function value: 0.425496
            <br>Iterations 11
            <br>Accuracy: 0.79
            <br>Precision: 0.8841463414634146
            <br>Recall: 0.7671957671957672
            <br>F1 Score: 0.8215297450424929
        </section>

        <h3><b>SCHRITTE 8: Modellverbesserung</b><br><br>
            Im Falle eines <b>OPTIMIERUNGSMODELLS</b> l√§sst sich ein LP-Modell am besten dadurch verfeinern, dass man
            sich ansieht, was dem aktuellen Modellrahmen fehlt. Das bedeutet im Allgemeinen eine weitere Ann√§herung an
            die reale Welt und eine geringere Abh√§ngigkeit von Annahmen.
            <br><br>
            Da lineare Annahmen in der Regel Ann√§herungen an eine optimierte L√∂sung sind, kommt die
            <b>Sensitivit√§tsanalyse</b> ins Spiel, mit der systematisch untersucht werden kann, wie empfindlich die
            L√∂sung eines Modells auf kleine √Ñnderungen der Daten, der Einschr√§nkungen oder sogar der Zielfunktion
            reagiert.
            <br><br>
            Es gibt jedoch einige Grenzen bei der Darstellung von realen Daten, insbesondere wenn es sich bei den zu
            analysierenden Informationen um Mitarbeiterdaten handelt. Es ist wichtig zu beachten, dass bei der
            Verarbeitung von Mitarbeiterdaten nur Details zur jeweiligen Rolle und zu den Arbeitspr√§ferenzen
            ber√ºcksichtigt werden und demografische Informationen v√∂llig au√üer Acht gelassen werden, da Entscheidungen
            zur Analyse der Mitarbeiterbindung ausschlie√ülich auf den Qualifikationen und der Erfahrung der Kandidaten
            basieren sollten, um das Potenzial f√ºr unbewusste Voreingenommenheit zu minimieren. Dieser Ansatz kann ein
            faireres und integrativeres Umfeld schaffen.
        </h3>

        <h3>In contrast, refinement of the logistic regression model can be achieved through ensemble techniques such
            as bagging, boosting, and stacking. These techniques involve combining the outputs of multiple models to
            improve overall predictive performance. By leveraging the strengths of various models, ensemble methods
            provide a more robust understanding of the data and can highlight areas where the initial model may fall
            short. This process not only strengthens the model‚Äôs generalizability but also enhances its ability to
            identify key retention patterns beyond what standard evaluation metrics might reveal.
            <br><br>
            Im Gegensatz dazu kann die Verfeinerung des logistischen Regressionsmodells durch Ensemble-Techniken wie
            Bagging, Boosting und Stacking erreicht werden. Bei diesen Techniken werden die Ergebnisse mehrerer Modelle
            kombiniert, um die Gesamtvorhersageleistung zu verbessern. Durch die Nutzung der St√§rken verschiedener
            Modelle bieten Ensemble-Methoden ein robusteres Verst√§ndnis der Daten und k√∂nnen Bereiche hervorheben, in
            denen das urspr√ºngliche Modell m√∂glicherweise nicht ausreicht.
            <br><br>
            Dieser Prozess st√§rkt nicht nur die Verallgemeinerbarkeit des Modells, sondern verbessert auch seine
            F√§higkeit, wichtige Bindungsmuster zu erkennen, die √ºber das hinausgehen, was die
            Standardbewertungsmetriken offenbaren k√∂nnten.
            <br><br>
            <b>FAZIT:</b><br>
            Das Datenanalyseprojekt hat erfolgreich zu zwei Modellen gef√ºhrt, die in der Praxis des Personalmanagements
            von Bedeutung sind. Das Modell zur Optimierung der Personaleinsatzplanung erm√∂glicht die Erstellung eines
            definierten Zeitplans, der an die spezifischen Bed√ºrfnisse von Managern und Mitarbeitern angepasst werden
            kann, was zu einer h√∂heren Produktivit√§t und Arbeitszufriedenheit f√ºhrt.
        </h3>

        <h3>In der Zwischenzeit hat sich das logistische Regressionsmodell f√ºr die Analyse der Mitarbeiterbindung als
            wirksam erwiesen, um Umwelt- und Verhaltensfaktoren zu ermitteln, die sich auf die Verweildauer der
            Mitarbeiter auswirken. Die Analyse zeigt, dass die Hauptursache f√ºr das fr√ºhzeitige Ausscheiden von
            Mitarbeitern die Diskrepanz zwischen den zugewiesenen Schichten und den Pr√§ferenzen der Mitarbeiter ist.
            Diese Erkenntnis unterst√ºtzt die Umsetzung flexiblerer Planungsstrategien als Mittel zur Verbesserung der
            Mitarbeiterbindung und des Engagements.
            <br><br>
            Kurz gesagt, unser Datenanalyseprojekt hat den Wert datengest√ºtzter Entscheidungsfindung im
            Mitarbeitermanagement aufgezeigt. Mithilfe dieser Modelle k√∂nnen Unternehmen ihre Zeitplanung optimieren,
            die Mitarbeiterbindung verbessern und ein positiveres Arbeitsumfeld f√ºr ihre Mitarbeiter schaffen.
            <br><br>
            Das Projekt zur Mitarbeiterbindung unterstreicht den Wert datengesteuerter Ans√§tze in der Personalplanung.
            Durch Optimierung und pr√§diktive Modellierung k√∂nnen Unternehmen ihre Planungspraktiken verfeinern, Risiken
            der Mitarbeiterbindung proaktiv angehen und ein produktiveres und f√∂rderliches Arbeitsumfeld schaffen.
        </h3>
    </div>
</section>

  <footer>
    <p>Erstellt von Adri√°n Ochoa Ferri√±o - 2023</p>
  </footer>

</body>
</html>